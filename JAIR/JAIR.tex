%
% File emnlp2016.tex
%

\documentclass[11pt,letterpaper]{article}
\usepackage{JAIR}
\usepackage{times}
\usepackage{latexsym}
\usepackage{url}
\usepackage{todo}

% Uncomment this line for the final submission:
\emnlpfinalcopy

%  Enter the EMNLP Paper ID here:
%\def\emnlppaperid{***}

% To expand the titlebox for more authors, uncomment
% below and set accordingly.
% \addtolength\titlebox{.5in}    

\newcommand\BibTeX{B{\sc ib}\TeX}


\title{Natural Language Processing in the Age of Deep Learning: A Review}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}
% If the title and author information does not fit in the area allocated,
% place \setlength\titlebox{<new height>} right after
% at the top, where <new height> can be something larger than 2.25in
% \author{Felix Hill \and Daniele Pighin\\
%  {\tt publication@emnlp2016.net}}

\date{}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}


\section{Introduction}
what this paper is about

\section{Backgrounnd}

History of neural language models

\newcite{bengio2003neural}
\newcite{miikkulainen1991natural}
\cite{miikkulainen1993subsymbolic}

\section{Language Modelling}

\section{Machine Translation}

\section{Machine Comprehension}

Following the development of recurrent neural networks capable of mapping from sequences to sequences and their successful application to machine translation, NLP researchers noticed that a similar approach could be effective in \emph{machine comprehension} style applications. The terms \emph{machine comprehension}, \emph{machine reading} typically refer to the broad class of task in which an algorithm has access to a passages of multiple sentences of prose (henceforth the \emph{context}) and a set of questions about the context of the passage (referred to here as \emph{queries}). The algorithm must select a correct (single or multi-word) answer to each question based on the information in the corresponding passage.  Machine comprehension have much in common with \emph{reading comprehension} questions that are used test human reasoning and/or linguistic proficiency in language learners. 

\subsection{Datasets and sub-tasks}
\paragraph{Deepmind News datasets} The current wave of neural network-based machine comprehension research was in large part triggered by the news comprehension dataset of~\newcite{hermann2015teaching}, compiled automatically from articles on the CNN and Daily Mail websites. News stories on both sites are summarised by a series of bullet points that summarise their main points. To develop their machine comprehension task,~\cite{hermann2015teaching} first identified all named entities in both the article and the bullet points using standard (NER) tools. A question in the CNN or Daily Mail dataset was then constructed by selecting an article, removing an entity from one of the bullet points in the summary and verifying that the entity does indeed appear in the article. To prevent the application of external knowledge to the task, the entities in the articles were replaced with symbolic identifiers. The task facing models is therefore to match the missing entity in each question to one of the symbolic identifiers identifiers in its article. The (smaller) CNN section of the Deepmind dataset alone consists of over 380,000 training and 4,000 test questions taked from over 90,000 distinct articles.

\paragraph{Facebook Children's Book Test (CBT)} The CBT is a multiple-choice test in which models must identify the missing word in a sentence from a children's book by using information from the previous 20 sentences in the book~\newcite{hill2015goldilocks}. The questions were selected such that both the missing word from the 21st sentence, and nine distractor candidate answers, appear at least once in the preceeding 20 sentences. The training and test questions are also (optionally) separated according to whether the missing word (and candidate choices) is a preposition, a verb, a common noun or a named entity. An important difference between the CBT and the Deepmind News dataset is that entities are not anonymised, so that general knowledge acquired from external resources can be used by models to improve performance on the test set. In total there are over 660,000 training and 10,000 test questions in the CBT, divided roughly equally according to the four question types. 

\paragraph{Stanford Question Answering (SQuAD) dataset} The SQuAD dataset,~\newcite{rajpurkar2016squad} crowdsourced English speakers to write questions that follow naturally from Wikipedia passages. Thus, models attempting the SQuAD task must answer authentic questions rather than cloze-style statements with missing words, bringing the task closer to genuine human reading comprehension. A further difference from the Deepmind and CBT datasets is that annotators were encouraged to write questions whose answers were multi-word segments in the article. For instance, the answer to the question \emph{what are two things that a computer always has} is the article segment \emph{a central processing unit (CPU) and some form of memory}. The SQuAD dataset consists of 90,000 training and 10,000 test questions. 

 \paragraph{TTI Who did What dataset} The Who did What dataset~\cite{onishi2016did} is based on articles in the English Gigaword Corpus. To compile the resource,~\newcite{onishi2016did} selected articles whose first sentence contained a person named entity. The person entity in question was removed from the sentence to form the question, the remainder of the article discarded, and a new (supporting) article retrieved that refers to the same person. To ensure they are sufficiently informative, the supporting articles were retrieved via an IE-style string matching procedure in which the question is used as the query. Questions were discarded if they could be answered by simple language model or frequency baselines, resulting in a bank of over 180,000 train and 10,000 test questions that humans can answer approximately 84\% of the time. As in the SQuAD dataset, answers in the Who did What dataset may consist of multiple words, although they are all person entities (\emph{the King of France}).

\paragraph{}Before the advent of neural machine comprehension models, research on machine comprehension typically relied on questions taken directly from real human reading comprehension questions~\cite{hirschman1999deep}. However, since such questions are usually produced by private education enterprises, large-scale datasets of this kind are not freely available for NLP research. Another notable forerunner to today's massive training and test resources is the \emph{MC Test}~\cite{richardson2013mctest}, which consists of 660 stories, and corresponding questions, all written by human annotators. The training data made available with the MC Test dataset is much smaller than more recent resources, and neural language models have not typically performed as well on this task as approaches that employ bespoke, hand-engineered symbolic features. However, recent work has shown that neural language models trained additionally on external data sources can perform competitively on the MC Test~\cite{trischler2016parallel}. Developing and understanding such transfer from general-purpose training data to specific small-scale applications is a key challenge for neural net approaches to machine comprehension and language understanding in general. 


\subsection{Models}
The first large-scale neural network approach to machine comprehension, the {\bf Deepmind recurrent readers}~\cite{hermann2015teaching}, exploits many of the techniques and principles of attention-based NMT (section XX). To answer a question from the Deepmind News dataset, the recurrent readers first apply a bidirectional RNN to the context article~\footnote{This encoding is similar to an attention-NMT model reading the source sentence, but in this case the bidirectional RNN covers multiple sentences}. This yields a variable-length distributed representation of the context containing a unique vector (the RNN hidden state) for each inter-word position in the article. 

In the \emph{attentive reader}, a single distributed representation of the query is computed using another bidirectional RNN, and used to compute attention weights over the set of context vectors. These are used to compute a single, fixed length (weighted sum) representation of the context, which is recombined with the query and fed to an output softmax optimised to predict the correct missing word from all possible words in the model's vocabulary.  In the \emph{impatient reader}, the attention weights, and hence a different weighted-sum representation of the article, is computed for each position in the bullet-point query. Thus, much like the attention-NMT model when processing a target sentence from the training set, the impatient reader can take a different perspective on the context depending on its current point of focus in the query. These perspectives are incremented to arrive at a (complex) single-vector representation of the article, based on which probabilities are computed for vocabulary words as potential answers (as in the attentive reader).

On the Deepmind News tasks, the recurrent reading models outperform a range of symbolic (non-neural) baselines, including those based on TFI-IDF and other techniques popular in information retrieval. They also outperform a neural baseline in which deep, bidirectional LSTM models read the query and the article in turn (as one long, conflated sequence) before predicting a possible answer.

This approach to large-scale machine comprehension was improved-upon by~\newcite{hill2015goldilocks} using a {\bf memory network}. Their model consists of four components. The first embeds the context in a finite set of distributed `memories'. The second weights these memories by matching them to a distributed representation of the query. The third computes a single representation of the memory as a weighted sum of the memories. The fourth predicts an output word via an output softmax over the model vocabulary. The network is trained end-to-end using a maximum likelihood objective. While a specific form of each of these components is also performed by the deepmind recurrent readers, the modular design of the memory network makes it possible to experiment with different strategies for each component.~\newcite{hill2015goldilocks} found particular methods for the first and second components that yielded improved performance on the Deepmind News dataset and strong benchmark performance on the CBT. The first component of the memory network that achieved this performance represented the context as a series of discrete 5-word windows.~\footnote{This representation probably allows the memory network to encode similar information to that encoded by a a bi-RNN at the point of reading the middle word in the window}. In the second component, it employed a `self-supervision' heuristic in which the weights in query and document representations were updated during training to directly increase the probability of retrieving the correct answer from the context relative to the other candidate answers. 

\newcite{kadlec2016text} continued the trend of improvement with the {\bf attention sum reader}, an elegant solution that combines effective aspects of both memory network and the Deepmind readers. Their approach is \emph{candidate-centric}: rather than estimating the probability of possible answers from a large vocabulary, it simply estimates the probability that some (or all) of the words or segments in the context is the correct answer. Consequently, it avoids the computation of an expensive and inefficient softmax over a large vocabulary, and can focus directly on locating a part of the context than indicates the correct answer. Specifically, the model reads the context using bidirectional LSTMs and stores representations focused on every candidate answer (the anonymous en will effectively preclude these simpler solutions andtities in the Deepmind News task or candidate answers in the CBT). A separate network represents the query (again with a bi-LSTM), and the candidates are scored based on their match with the query representation. The model is then simply trained to score correct answers above other candidates.  

The attention sum reader underlines the value of bidirectional recurrent nets in providing variable (`soft') windows of focus over unstructured text. Together with the self-supervision heuristic used by~\newcite{hill2015goldilocks} to train memory networks, it also highlights the importance (and the challenge) of learning to search over potentially unstructured information with continuous, gradient-based learning methods. While the candidate-centric models can overcome this issue on the current set of machine comprehension tasks, they would not work in a more general QA setting where the correct answer does appear directly in the context. 

Since the work of~\newcite{kadlec2016text}, various contributions have incremented the state-of-the-art on both the CBT and Deepmind News datasets. Some of these approaches derive improvements from richer representation of the context:  \cite{kobayashi2016dynamic,weissenborn2016separating,sordoni2016iterative}. Others experiment with more sophisticated ways to access the context, including hierarchical attention~\cite{cui2016attention}, repeated memory access~\cite{cui2016attention,weissenborn2016separating,dhingra2016gated,sordoni2016iterative} and explicit entailment-style reasoning operations~\cite{trischler2016natural}. Following the success of the attention sum reader~\newcite{kadlec2016text},  all of the aforementioned models are candidate-centric rather than predicting answers from their full vocabulary. At the time of writing, the best performing model on the CBT is that of~\cite{sordoni2016iterative}, which combines a bi-RNN context representations with iterative memory access. The current best on the Deepmind News task is achieved by~\newcite{dhingra2016gated}, whose model uses a multiplicative operation to match query representations with increasingly high-level views of the context.\footnote{An excellent repository for many of the datasets, papers and results discussed in this section can be found at \url{http://uclmr.github.io/ai4exams/eqa.html}}

While the greater architectural sophistication of these latter models yields small improvements on the Deepmind News and CBT tasks, it may be that the more sophisticated datasets are needed to see the advantages of these reasoning components. As highlighted by~\newcite{chen2016thorough}, these tasks can be susceptible to simple solutions that do not seem to rely on principled semantic inference or reasoning. As such, the SQuAD and Who said What datasets, which are just starting to be tackled by the research community, may play an important part in guiding the development of models capable of increasingly human-like text understanding.

\section{Entailment}

\section{Dialogue and interactive QA systems}

Dialogue systems aim to model human discourse or conversation in a realistic way while interacting with human users. The applications of dialogue systems range from more the conversational, such as chatbots and online agents,, to the more goal driven, such as a telephone restaurant or hotel reservation systems. Research into dialogue systems extends back to the earliest days of natural langage processing, with systems such as ELIZA \cite{weizenbaum1966eliza}, whose rule-based responses gave a surprising sense of genuine understanding.     

The age of deep learning has not left dialogue research untouched. Recent approaches to dialogue involving deep neural networks can be roughly divided into two camps: those with the explicit objective of yielding applicable systems with clear and specific communication objectives (such as completing a restaurant booking), and those whose primary aim is to converse with users in a natural, human-like way, but whose function may be less well-defined. Beyond these two areas of core dialogue research, we also review a third body of research: \emph{interactive QA systems}. These systems align with goal-driven dialogue systems in modeling interactions with a clear function (eliciting or providing a fact or information). However, like conversational agents they aim to cover wide or even unrestricted semantic domains.     

\subsection{Goal-driven dialogue systems}
Research into goal driven dialogue systems has typically avoided placing all of the burden of representation learning onto their component neural networks~\cite{henderson2014word,mrkvsic2015multi,wen2015stochastic,wen2015semantically}. Instead, these approaches exploit a hand-coded symbolic representation of their internal semantic state. Because these models are applied to comparatively narrow functional domains (such as IT support, restaurant reservation or hotel booking), it is possible for humans to encode all possible dialogue states, by means of an ontology of allowable concepts, predicates and values. For instance, in the Cambridge Restaurant System~\cite{wen2016network} there are 99 possible restaurants, each characterised by six predicates (\emph{food, pricerange, area, address, phone, postcode}) with constrained sets of possible values. 

Once such an ontology has been defined, there are two components of the dialogue problem to which neural networks can be applied in such systems. The first is \emph{state tracking}; the task of updating the current semantic state of the system based on some previous state and some incoming language. The second is \emph{response generation}; the task of producing language that is useful to the user given the current state.~\footnote{We assume that systems process and produce written language in this review, but one or both of these components can be extended to receive input or produce output as raw speech.}

\newcite{henderson2014word} propose employing separate RNNs for each possible predicate in the dialogue state ontology. As the dialogue proceeds, each RNN updates the likelihood of its predicate taking a particular value based on its previous internal state and new linguistic input (in the form of ranked hypotheses from an ASR system). While the model is trained on a very small amount of data (1612 short dialogues), the low dimensional output space for each RNN (the possible values for each dialogue state predicate) and an autoencoding initialisation procedure yield stronger performance than previous approaches to the same task based on bayesian generative graphical models. \newcite{mrkvsic2015multi} builds on this approach, by introducing a single network that predicts the values of all predicates in the dialogue state. It is thus able to model the likely interactions between concept features, such as the address of a restaurant and its price range. However, \newcite{mrkvsic2015multi} show that initialising multiple RNNs in this holistic way before later specialising them to predict the value of a particular predicate yields better performance than training a single generalist network. A similar technique is also applied to train a network that is able to generalise effective across multiple semantic domains (and hence state representations and ontologies). \newcite{mrkvsic2016neural} later show that feed-forward networks with access to only one prior time-step in the chain of dialogue interactions can be equally or more effective than RNNs for dialogue state tracking. 

Goal-driven dialogue systems have also benefited from the application of neural networks to the task of mapping from dialogue state representations to plausible linguistic output. \newcite{wen2015stochastic,wen2015semantically} apply RNNs to the task of natural language generation conditioned on dialogue states. This application mirrors the RNN decoding in the NMT systems described in section (X), which also produced striking results in image caption generation [REFs]. Generation for goal-driven dialogue systems differs in two key aspects from these applications: models typically have access to much less training data, and must be conditioned on symbolic rather than distributed semantic representations. \newcite{wen2015stochastic} overcome the former challenge by keeping network size very small (80 units in the hidden layer), making units dropout [REF] with a high (50\%) probability, and using pre-trained word embeddings in the output layer. \newcite{wen2015semantically} present an elegant solution to the latter obstacle by allowing a one-hot representation of the (symbolic) dialogue state to control a gate of an LSTM module in the generating RNN, which effectively moderates the flow of information from the symbolic representation to the word-by-word generation process. \newcite{wen2015stochastic} also observe improvements by re-ranking the top-n candidate sentences produced by their models. During training this is done by means of a backward RNN conditioned on future dialogue states. At test time, they use an (unconditional) convolutional neural language model fit to the utterances in the training data. 

A key challenge for goal-driven dialogue systems is obtaining training data, which must consist of conversations aligned with corresponding dialogue states. Even with creative crowdsourcing methods~\cite{wen2016network}, the sparsity of such data will be prohibitive for deep learning methods unless the number of possible dialogue states is small. While such ontologies can be defined for restricted domains such as the restaurants in a given city, it is less clear whether the approach is scalable, or whether hand-crafted semantic ontologies could be constructed for the full range of desirable dialogue domains and applications. 

\todo{Insert a table 1 from \cite{wen2015semantically} to show a typical ontology}

\subsection{Conversational dialogue models}
The previous section demonstrates that neural networks, and RNNs in particular, can be useful components of traditional dialogue systems. However, the promise of deep learning is that, eventually, internal representations like the semantic `state' of a dialogue system can be inferred automatically from data. Such a step would  obviate the need for expensive, domain-specific ontology engineering. Nonetheless, we are some way from training dialogue systems that are both capable of learning their internal representations and are of practical use to users with a concrete objective. Attempts to meet this challenge constitute a vibrant area of current research. The interface between semantics, language learning and dialogue promises to be one of the most interesting applications of deep learning and language technology in the coming years. 

As with a growing number of NLP application areas, an important basic element of many data-driven, conversational dialogue models is the sequence-to-sequence neural network originally applied to speech recognition and MT. Given a (sufficiently large) corpus transcribing an ordered set of discrete utterances \(u_1 \dots u_n\), perhaps coming from different speakers, a sequence to sequence architecture can model the function mapping one utterance to the next utterance simply by treating the data \(\{u_1, u_2\}\), \(\{u_2, u_3\}\) etc. as \{source, target\} pairs. Once trained in this way, a sequence-to-sequence model given an utterance \(u\) can generate a response utterance \(v\) by approximating the highest probability sentence from the output distribution, much as with NMT models. As shown by both~\cite{sordoni2015neural} and~cite{vinyals2015neural}, models trained in this way capture aspects of typical conversational flow in a compelling way. 

However, there are fundamental limitations to modelling dialogue with a (deterministic) function in this way. Unlike in MT, the mapping between conversational utterances and their responses is evidently not one-to-one - a wide range of possible utterances can be met with the response \emph{I don't know}. Further, to an even greater extent than in MT, in human dialogue there is no single `correct' response to any particular utterance. Motivated by these observations,~\cite{shang2015neural} train a sequence-to-sequence model on a multi-response corpus consisting of social media (Weibo) posts together with set of \(n\) resulting comments, where typically \( 1 \leq n \leq 10\). In other words, the model is trained explicitly to approximate a one-to-many function. Comparing models based on human judgements of their grammaticality, consistency, informativeness etc,~\cite{shang2015neural} find that sequence-to-sequence models cope well in this training regime, outperform a symbolic statistical MT-style model, and that sequence-to-sequence models with attention (Section XX) outperform those without attention. In a related contribution, ~\newcite{li2015diversity} observe an undesirable characteristic of sequence-to-sequence models trained on dialogue corpora. The prior probability of generic or uninformative responses such as \emph{I don't know} in such a corpus is always comparatively high, since such responses can appropriately follow almost any utterance. Therefore, at test time, dialogue sequence-to-sequence models trained, like the best-perfoming NMT mdoels, to maximise the likelihood attributed to the training data produce uninformative responses with high regularity. ~\newcite{li2015diversity} propose a way to mitigate this by down-weighting the importance of this prior probability in the training data. They find that humans judge the output of models to be more interesting and informative as a consequence of being trained in this way.~footnote{See BENGIO and RANZATO for other creative ways of improving the output of sequence prediction models}. 	

Another challenge in modelling dialogue is the long-term interactions between utterances. A typical human conversation is full of references to entities and facts mentioned previously in the same conversation. However, RNNs trained on human dialogue data generate utterances that clearly contradict those made several turns earlier in the dialogue, yielding conspicuously non-human output [INSERT EXAMPLE]. Moreover, using LSTMs or GRUs to augment the sensitivity of RNNs to longer temporal dependencies does not effectively resolve the issue.~\newcite{sordoni2015neural} instead employ a feedforward (bag-of-words) architecture to encode all previous dialogue utterances in a single vector, which is concatenated to a representation of the latest utterance (effectively giving equal status to the current utterance and all previous utterances combined). This combined representation is then mapped to a suitable response using a standard RNN decoder. \newcite{sordoni2015neural} finds that the addition of this longer-term perspective improves performance compared with a model that responds based on the most recent utterance alone. \newcite{serban2016building} extend this idea with a two-level RNN architecture involving three components. The lower RNN encodes utterances much as in a standard sequence-to-sequence model. A dialogue tracking RNN reads the final hidden state of this encoder (a distributed representation summarising its content), updates its own internal state and produces some output representation. A decoder RNN then predicts a suitable (linguistic) response given this output of the state tracking RNN. This approach is more expressive than that of \cite{sordoni2015neural} in two important ways. First, because it reads all linguistic input with RNNs it can encode order-dependent aspects of all utterances. Second, the state-tracking RNN allows the model to learn (and generalise over) common sequential dependencies in high-level semantic flow of the conversation.\footnote{In this sense, the highest level network in~\cite{serban2016building} is analogous to the specialised state-tracking RNNs proposed by~\newcite{mrkvsic2015multi}} Importantly, while the two-level model involves three RNNs, it can be trained fully end-to-end like any other sequence-to-sequence model, so that the component networks are optimised jointly to increase the likelihood of modelling observed conversation data. Thanks to its greater expressivity, however, the two-level RNN exhibits lower perplexity on held-out conversation data than both the standard sequence-to-sequence approach and the (flatter) contextual model of~\cite{sordoni2015neural}.

The most recent contributions have taken several new and promising directions in addressing the myriad challenges of modelling human dialogue. Much of this work concerns narrowing the gap between hand-engineered goal-driven models and fully end-to-end approaches, and, specifically, giving data-driven architectures more hope of executing the semantic reasoning and inference necessary to be a useful tool for human users.  
- Serban (from Bowman) - variational model. Also Yishu and Lei perhaps. Refer to Chung. HOW DOES A VAE REALLY WORK?
- Papers cited in latest Serban. 
- Li reinforcement learning approach.

Finally,~\cite{li2016persona} tackle the problem of giving each interlocutor as a distinct persona, by introducing additional latent representations (embeddings) for storing information associated each of the contributors in a conversation. The response of a given speaker can then be generated conditioned on both on the previous utterances and the appropriate persona embedding, which yields greater within-person consistency in the model output. For instance, the model output for Person 1 might claim to be British and later to like fish and chips, whereas the responses of Person 2 indicate that she is Italian and, later, that she likes pizza. 

\cite{kalchbrenner2013recurrent} Dialogue act classification (cannot generate from this model, so maybe just mention out of politeness . 

2) End-to-end / learning from raw data / latent semantics
- requires much bigger data
- acquire latent representations of state / topic / desire
- solution could scale to many domains provided data available but perhaps a long way off
- evaluation harder, can't ask whether the goal was achieved, since goal not even clear. 

\subsection{Simulated data approaches}

Surveying the landscape of dialogue research, it is clear that both goal-directed and end-to-end data-driven systems suffer from important limitations that could prevent each respective approach from yielding widely-adopted, general purpose dialogue systems. This has led to a strand of recent research in which end-to-end neural network agents (with no task-specific hand engineering) are trained on pseudo-natural, but algorithmically generated, language data designed to contain certain information and/or exemplify particular reasoning patterns. This approach can be considered as a `hybrid' between goal-driven and fully data-driven approaches. Hybrid approaches based on simulated data aim to couple the scalability, domain-adaptation, cost and naturalness advantages of end-to-end approaches with many of the benefits of goal-driven systems, such as direct functional utility and clear performance measurement.

An important motivating insight for the hybrid approach is that there are distinct types of reasoning or inductive step required by dialogue agents to arrive at useful output, and that these types can be represented by canonical or prototypical dialogue exemplars. These abstract reasoning patterns differ from the symbolic semantic states specified by the developers of goal-driven dialogue systems in that they are in principle pertinent to dialogue from any linguistic or semantic domain. For example, the `two supporting facts' class exemplifies reasoning that straightforwardly combines information from two previous utterances in some dialogue in order to produce a sensible response. The `simple negation' class explicitly requires understanding that propositions in some dialogue are either negated or not in order to arrive at a satisfactory response.~\newcite{weston2015towards} define ten classes of reasoning intended to cover many of the common types of reasoning found in dialogues between users and agents and provide algorithmically-generated examplars for each class (SEE TABLE X). Such data-generation requires X and has limitations such as Y. Nevertheless, it is cheaper and easier than Z.   

\cite{dodge2015evaluating} Bridge gap between goal-driven and end-to-end. Uses templates to generate data from either QA (movie questions) or recommendation (I like x, y z, you should try X). 

\cite{bordes2016learning} (NOT PUBLISHED) Bridge gap between goal-driven and end-to-end (chit-chat). test the capacity of end-to-end dialog systems for conducting goal-oriented
dialog Proposes ways to make the data-driven approach more structured. these five tasks cover several dialog stages and test if models can learn various abilities such as
performing dialog management, querying KBs, interpreting the output of such queries to continue
the conversation or dealing with new entities not appearing in dialogs from the training set. Restaurant domain. No new model but try memory networks. Use the training set to teach the model how to interact with the KB - but test it on entities (restaurants) that are not in the training set. Also adapt the dialogue state tracking data of Henderson to this format (by creating output but not using the labelled state for each utterance). 

\cite{miller2016key} Key value networks. Read a key, return a value. Also hashing - narrow down the memory based on symbolic operation on possible content. Idea is to bridge gap between KB and free text. 

can mention DefGen here perhaps. Mostly Weston memory nets QA-style stuff. NTM? 

Cite latest Weston paper.

\subsection{Datasets}
Any recording or transcript of conversation can potentially be a useful training resource for dialogue systems. Consequently, there is a great variety of potentially relevant corpora, which are surveyed in detail by~\cite{serban2015survey}. We therefore outline only those that have proved useful to date in training the more recent network-based dialogue models.

The Dialogue State Tracking Challenge (DSTC) corpora have proved to be an important resource and testbed for goal-driven dialogue models, such as the RNN-based state tracker of~\newcite{henderson2014word}. [DOES MRKSIC USE THESE TOO?] Each of these corpora contains between 3,000 and 15,000 dialogues recording interactions between humans and rudimentary dialogue systems, and each is focused on a different practical domain. For instance, DSTC 1 transcribes interactions with an automatic bus ride system, and DSTC 3 records interactions with a restaurant booking system.~\cite{wen2015semantically} extend this by [SAY HOW THEY EXTEND IT].  

Dialogue systems that do not rely on hand-engineered semantic states typically require much more raw data to train. Research on end-to-end, data-driven conversational models has therefore tended to exploit larger datasets that created specifically for training dialogue systems, such records of social media posts, tweets or comments. Work that uses such resources include the encoder-decoder model of~\cite{shang2015neural}, whose Sina Weibo Corpus~\cite{shang2015neural} records multiple responses (from different users) to each of 4.5m initial postings.~\newcite{sordoni2015neural},~\newcite{li2015diversity},~\newcite{serban2016multiresolution} all experiment with similar datasets containing over 100 million context-message-response or A-B-A triples extracted from Twitter. 

\subsection{Discussion}

There is are even greater difficulties to overcome, and apparently even less consensus among researchers, when it comes to evaluating data-driven or conversational dialogue models. XX compare models based on their average per-word perplexity on some held-out data similar to the training set. Such an evaluation framework reduces the task to language modelling for a particular domain, and has several limitations. First, it does not measure the capacity of the system to generate an answer given some input, but merely to quantify the relative quality of possible responses. Second, a model at a given point in dialogue is not rewarded for exhibiting low perplexity for any responses beyond the single response in the test data, even though in practice numerous responses may be viable, particularly since no explicit goal is defined for the dialogue. Several studies have overcome the first of these limitations by requiring models to generate ranked lists of responses, e.g. by approximating MAP estimates from the output distribution with beam search (as in MT systems). The contents of such a list can be compared with the correct test response using metrics such as BLEU or METEOR. However, such evaluations suffer particularly from the second limitation, exacerbated by the fact that BLEU-style metrics are based simply on word or n-gram overlap. This means that even if a model response matches is grammatical and means the same as with the test response, the model will not be credited unless precisely the same words are used. Perhaps unsurprisingly, then, it has been observed that BLEU-style evaluations exhibit negligible correlation with human ratings of system quality [REF]. Attempts to mitigate this critical flaw by using pre-trained word embeddings to generalise output and test responses have so far had mixed success [REF].   

*data-driven*
perplexity (clearly odd)
blue / meteor vs. held-out data (shown to be a problem)
human rating (clearly optimal)
prediction / answer selection (Ubuntu) - not so stupid

*goal-driven*
state-tracking: classification of held-out data 
generation: humans rate in terms of naturalness (not great)
humans rate in terms of function using ontology - better.

*QA-systems*

The spectrum of structured to open, the NN philosophy etc. 
ultimately gunning at the same thing: in 1) they form a narrow symbolic channel with which to reason and track behaviour. modular. but in that case the NN is just a smooth function aproximator which happens to yield a satisfactory smoothness. Not solving the task itself. 
- a typical in-domain semantic state is very small - 64 acts? 



\cite{su2016line}




\cite{liu2016not}
\cite{su2015learning}


%datasets
\cite{lowe2015ubuntu}


\section{Representation Learning}
\subsection{Parsing}
\subsection{Distributed representations}

\section{Summarisation}

\section{Active Learning}

\cite{weston2016dialog} Simulated conversation in which questions are asked at the end, and the goal is to see how well agents are at learning from the dialogue, given different reward and cost function setups. 
Angeliki paper

\cite{li2016deep} %RL + dialogue


\section{Miscellaneous Others}










\bibliography{JAIR}
\bibliographystyle{JAIR}

\end{document}
